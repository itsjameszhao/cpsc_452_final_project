{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classifier.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPewb0RkmX2WYBzQ6IxfaWF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3fmH618l5JL2"},"outputs":[],"source":["import torch\n","import torch.nn as nn  # neural network modules\n","import torch.nn.functional as F  # activation functions\n","import torch.optim as optim  # optimizer\n","from torch.autograd import Variable # add gradients to tensors\n","from torch.nn import Parameter # model parameter functionality\n","import sklearn \n","\n","import torchvision\n","import torchvision.datasets as datasets\n","from torchvision.utils import save_image\n","from torchvision import transforms\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import time\n","import tqdm"]},{"cell_type":"code","source":["class FCN(nn.Module):\n","    def __init__(self, input_dim):\n","        super(FCN, self).__init__()\n","        \n","        self.input_dim = input_dim\n","\n","        self.layer1 = nn.Linear(input_dim, 4000)\n","        self.layer2 = nn.Linear(4000, 2000)\n","        self.layer3 = nn.Linear(2000, 1000)\n","        self.layer4 = nn.Linear(1000, 500)\n","        self.layer5 = nn.Linear(500, 250)\n","        self.layer6 = nn.Linear(250, 100)\n","        self.layer7 = nn.Linear(100, 50)\n","        self.layer8 = nn.Linear(50, 20)\n","        self.layer9 = nn.Linear(20, 1)\n","\n","    def forward(self, x):\n","        h1 = F.relu(self.layer1(x))\n","        h2 = F.relu(self.layer2(h1))\n","        h3 = F.relu(self.layer3(h2))\n","        h4 = F.relu(self.layer4(h3))\n","        h5 = F.relu(self.layer5(h4))\n","        h6 = F.relu(self.layer6(h5))\n","        h7 = F.relu(self.layer7(h6))\n","        h8 = F.relu(self.layer8(h7))\n","        h9 = F.relu(self.layer9(h8))\n","\n","        return F.sigmoid(h9)"],"metadata":{"id":"iJ8EeqU65VQt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Cqc_c5ehpxn_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Training function\n","def train_epoch_classifier(encoder, decoder, classifier, device, dataloader, loss_fn, optimizer):\n","    # Set train mode for both the encoder and the decoder\n","    encoder.eval()\n","    decoder.eval()\n","    train_loss = []\n","    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n","    for image_batch, labels in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n","        # Move tensor to the proper device\n","        image_batch = image_batch.to(device)\n","        # Encode data\n","        # print(f\"Shape of image batch is {image_batch.shape}\")\n","        encoded_data = encoder(image_batch)\n","        # Decode data\n","        decoded_data = decoder(encoded_data)\n","        output = classifier(decoded_data)\n","        # Evaluate loss\n","        loss = loss_fn(output, labels)\n","        # Backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # Print batch loss\n","        train_loss.append(loss.detach().cpu().numpy())\n","\n","    return np.mean(train_loss)\n","\n","\n","### Testing function\n","def test_epoch_classifier(encoder, decoder, classifier, device, dataloader, loss_fn):\n","    # Set evaluation mode for encoder and decoder\n","    encoder.eval()\n","    decoder.eval()\n","    classifier.eval()\n","    with torch.no_grad(): # No need to track the gradients\n","        # Define the lists to store the outputs for each batch\n","        conc_out = []\n","        conc_label = []\n","        for image_batch, test_labels in dataloader:\n","            # Move tensor to the proper device\n","            image_batch = image_batch.to(device)\n","            # Encode data\n","            encoded_data = encoder(image_batch)\n","            # Decode data\n","            decoded_data = decoder(encoded_data)\n","            output = classifier(decoded_data)\n","            # Append the network output and the original image to the lists\n","            \n","        # Evaluate global loss\n","        val_loss = loss_fn(output, test_labels)\n","    return val_loss.data"],"metadata":{"id":"aLZBabHC7ONz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 200\n","diz_loss = {'train_loss':[],'val_loss':[]}\n","for epoch in range(num_epochs):\n","   train_loss = train_epoch_classifier(encoder,decoder,device,train_loader,loss_fn,optim)\n","   val_loss = test_epoch_classifier(encoder,decoder,device,test_loader,loss_fn)\n","   print('\\n EPOCH {}/{} \\t train loss {} \\t val loss {}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n","   diz_loss['train_loss'].append(train_loss)\n","   diz_loss['val_loss'].append(val_loss)\n","\n","   scheduler.step(val_loss)\n","\n","torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': encoder.state_dict(),\n","            'optimizer_state_dict': optim.state_dict(),\n","            }, \"./data/most_recent_encoder.h5\")\n","\n","torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': decoder.state_dict(),\n","            'optimizer_state_dict': optim.state_dict(),\n","            }, \"./data/most_recent_decoder.h5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4UgBioTx5jQ8","executionInfo":{"status":"ok","timestamp":1650574398063,"user_tz":240,"elapsed":13,"user":{"displayName":"Shaurya Kumar","userId":"15146036230092953043"}},"outputId":"ef0b30d0-cee1-4016-f595-9977c04a200c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2048.0"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","data = torch.rand((1, 50,50))\n","layer = nn.Conv2d(1, 1, kernel_size=4, stride=1, padding=1)\n","layer(data).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CIuDVlJ3HFl2","executionInfo":{"status":"ok","timestamp":1650913710502,"user_tz":240,"elapsed":275,"user":{"displayName":"Shaurya Kumar","userId":"15146036230092953043"}},"outputId":"e20c765f-dc04-4776-a36f-bccb91c84340"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 49, 49])"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["data = torch.rand((1, 50,50))\n","layer = nn.Conv2d(1, 1, kernel_size=8, stride=5, padding=0)\n","layer(data).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v1KvR8JTHKmT","executionInfo":{"status":"ok","timestamp":1650913823390,"user_tz":240,"elapsed":8,"user":{"displayName":"Shaurya Kumar","userId":"15146036230092953043"}},"outputId":"29b09240-a335-481e-94ff-524f0a8a290d"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 9, 9])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["data = torch.rand((1, 50,50))\n","layer = nn.MaxPool2d(kernel_size=10, stride=2, padding=2)\n","layer(data).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jWWP2GxQIm5o","executionInfo":{"status":"ok","timestamp":1650913891992,"user_tz":240,"elapsed":427,"user":{"displayName":"Shaurya Kumar","userId":"15146036230092953043"}},"outputId":"871299be-56f1-4b01-81d7-40b5d889e534"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 23, 23])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["data = torch.rand((1, 50,50))\n","layer = nn.MaxPool2d(kernel_size=2, stride=1, padding=0)\n","layer(data).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eoh18relInPZ","executionInfo":{"status":"ok","timestamp":1650913902283,"user_tz":240,"elapsed":277,"user":{"displayName":"Shaurya Kumar","userId":"15146036230092953043"}},"outputId":"035b9db9-a55f-4dec-eb27-ab105d5c81fc"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 49, 49])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":[""],"metadata":{"id":"j3vjU_ANIvua"},"execution_count":null,"outputs":[]}]}